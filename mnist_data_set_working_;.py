# -*- coding: utf-8 -*-
"""MNIST data set working ;

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16OMiDmR4b5i5fuvhnwjn0KVLEKurjNQN
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import tensorflow
#import tensorflow.keras.datasets
from tensorflow.keras.datasets import mnist

from tensorflow.keras.utils import to_categorical

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten

(x_train,y_train),(x_test,y_test) =  mnist.load_data()

x_train.shape

single_image=x_train[0]
plt.imshow(single_image)

print(y_train)
y_train.shape

#preparing training data for y
y_data_for_training = to_categorical(y_train,num_classes=10)
y_data_for_testing = to_categorical(y_test,num_classes=10)

print(y_train.shape,y_data_for_training.shape)
print(y_test.shape,y_data_for_testing.shape)

# normalisind data fro x,try to devide it only once for scaling between 0 to 1
x_train = x_train/255
x_test  = x_test/255

#printing image using plt.imshow
plt.imshow(x_train[0])





#batch_size,width,height,color_channels
x_train = x_train.reshape(60000,28,28,1)
x_test  = x_test.reshape(10000,28,28,1)

# creating model
model = Sequential()

model.add(Conv2D(filters=128,kernel_size=(3,3),input_shape=(28,28,1),activation="relu"))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(128,activation="relu"))


# OUTPUT LAYER
model.add(Dense(10,activation="softmax"))

model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])

from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor = 'val_loss',patience=1 )

print(x_train.shape,y_train.shape)
x_test.shape,y_test.shape

#model.fit(x_train,y_data_for_training,epochs=10,validation_data=(x_test,y_data_for_testing),callbacks=[early_stopping])

model.fit(x_train,y_data_for_training,epochs=10,validation_split=0.2,callbacks=[early_stopping])

plotting = pd.DataFrame(model.history.history)
plotting

plotting[['loss','val_loss']].plot()

plotting[['accuracy','val_accuracy']].plot()

model.evaluate(x_test,y_data_for_testing)

import numpy as np

prediction_classes=model.predict_classes(x_test)

x_test=x_test.reshape(10000,28,28)
plt.imshow(x_test[0])

from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,prediction_classes))
print(confusion_matrix(y_test,prediction_classes))

